apiVersion: logging.banzaicloud.io/v1beta1
kind: Flow
metadata:
  name: s3-flow
  namespace: hcf
spec:
  filters:
    - tag_normaliser:
        format: ${namespace_name}.${pod_name}.${container_name}
  localOutputRefs:
    - s3-output
---
apiVersion: logging.banzaicloud.io/v1beta1
kind: Output
metadata:
  name: s3-output
  namespace: hcf
spec:
  s3:
    aws_key_id:
      valueFrom:
        secretKeyRef:
          name: logging-s3
          key: awsAccessKeyId
    aws_sec_key:
      valueFrom:
        secretKeyRef:
          name: logging-s3
          key: awsSecretAccessKey
    s3_bucket: logging-hcf
    s3_endpoint: https://sfo3.digitaloceanspaces.com
    s3_region: us-east-1
    path: logs/%Y-%m-%d/${tag}/
    buffer:
      timekey: 60m
      timekey_wait: 30s
      timekey_use_utc: true
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: log-cleanup
  namespace: hcf
spec:
  concurrencyPolicy: Allow
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - command:
            - /bin/bash
            - -c
            - |
              set -e
              mkdir ~/.aws
              cat <<EOF >~/.aws/config
              [default]
              output = json
              region = us-east-1
              EOF
              cat <<EOF >~/.aws/credentials
              [default]
              aws_access_key_id = ${AWS_ACCESS_KEY}
              aws_secret_access_key = ${AWS_SECRET_KEY}
              EOF
              set -x
              aws s3 --endpoint=https://${AWS_ENDPOINT} ls s3://${AWS_BUCKET}/ | while read -r line; do
                  createDate=`echo $line|awk {'print $1" "$2'}`
                  createDate=`date -d"$createDate" +%s`
                  olderThan=`date --date "90 days ago" +%s`
                  if [[ $createDate -lt $olderThan ]]; then
                      filename=`echo $line|awk {'print $4'}`
                      if [[ ! -z "$filename" ]]; then
                          aws s3 --endpoint=https://${AWS_ENDPOINT} rm s3://${AWS_BUCKET}/$filename
                      fi
                  fi
              done
            env:
            - name: AWS_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: logging-s3
                  key: awsAccessKeyId
            - name: AWS_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: logging-s3
                  key: awsSecretAccessKey
            - name: AWS_ENDPOINT
              value: sfo3.digitaloceanspaces.com
            - name: AWS_BUCKET
              value: logging-hcf
            image: denartcc/cli:v1.1.2-1
            imagePullPolicy: Always
            name: backup
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
          dnsPolicy: ClusterFirst
          restartPolicy: OnFailure
          schedulerName: default-scheduler
          terminationGracePeriodSeconds: 30
  schedule: 0 0 * * *
  successfulJobsHistoryLimit: 3
  suspend: false
